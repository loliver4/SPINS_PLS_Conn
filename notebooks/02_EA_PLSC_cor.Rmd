---
title: "02_EA_PLSC"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(splitstackshape)
library(tidyr)
library(dplyr)
library(corrr)
library(psych)
library(TExPosition)
library(data4PCCAR)
library(PTCA4CATA)
library(tableone)
library(corrplot)
library(mice)
library(ggplot2)

```

```{r}
# set working dir
setwd("/scratch/loliver/SPINS_PLS_Conn")

# find EA residual time series files  # pattern glob2rx("*_EA_6mm_noGSR_glasser_meants.csv") # 6mm
# _up files are the updated time series after fixing the EA trigger issues
files_EA_resid_ts <- list.files(path= ".", recursive=T, full.names=F, pattern="^.*_EA_2mm_noGSR_glasser_meants_up\\.csv$")

# confirm csvs aren't empty
files_EA_resid_ts[file.size(files_EA_resid_ts) == 0]

# create list of IDs
ptlist <- paste("SPN01", substring(files_EA_resid_ts,5,7), substring(files_EA_resid_ts,8,11), sep = "_")

# read in time series files
resid_ts <- lapply(files_EA_resid_ts, read.csv, header=F)

# transpose dfs
resid_ts <- lapply(resid_ts, t)

# Name dfs with participant IDs
names(resid_ts) <- ptlist

```

```{r}
# read in new exclusion list based on EA task, motion, and imaging (fmriprep and ciftify) QC (see SPINS_EA_QC.R)
# also checked old participants.tsv file to make sure nothing being missed
exclude_list <- read.csv(file="/projects/loliver/SPINS_PLS_Conn/data/processed/QC_exclusion_list_04-26-2021.csv", header=F)

resid_ts <- resid_ts[!(names(resid_ts) %in% exclude_list$V1)]

# read in  early termination IDs - check to see who remains 
early_term <- read.csv(file="/projects/loliver/SPINS_PLS_Conn/data/processed/spins_termination_info_11-20-2020.csv", header=T)

# 7 participants remain
# CMH_0009 exclude due to high hba1c
# CMP_0178 exclude due to positive UDS (only determined after completion)
# CMP_0183 exclude due to no cog data - unable to contact
# CMP_0202 exclude due to no cog data - did not want to continue
# ZHH_0019 exclude due to positive UDS
# ZHH_0020 exclude due to high hba1c
# ZHP_0162 exclude due to no cog data - did not want to continue

early_term_exc <- c("SPN01_CMH_0009","SPN01_CMP_0178","SPN01_CMP_0183","SPN01_CMP_0202","SPN01_ZHH_0019","SPN01_ZHH_0020","SPN01_ZHP_0162")

resid_ts <- resid_ts[!(names(resid_ts) %in% early_term_exc)]

# there are notes about CMH_0136 falling asleep/eyes being closed, but they made presses throughout and performed fairly well (and passed EA task QC), so a non-issue
# similarly, notes suggest CMH_0146 may have had difficulty, but EA ratings/pattern indicate all fine
# ZHH_0038 no EA
# remove CMH_0048 from include list due to lack of activation being detected across multiple ROIs?? - DC this old note

```

```{r}
# find circles onsets for each participant
setwd("/scratch/loliver/SPINS_PLS_Conn")
files_circles <- list.files(path= ".", recursive=T, full.names=F, pattern="^.*_circles\\.1D$")

# create list of IDs
circ_ptlist <- paste("SPN01", substring(files_circles,5,7), substring(files_circles,8,11), sep = "_")

# read in circles files
circles <- lapply(files_circles, read.csv, header=F, sep=" ", colClasses=c(NA, NA, "NULL"))
names(circles) <- circ_ptlist

# get circles onset times into same row, adding 546 s per run and dividing by 2 as TRs are 2s
circles_times <- list()

for (i in names(circles)) {
  circles_times[[i]] <- round((cbind(circles[[i]][1,],(circles[[i]][2,])+546,(circles[[i]][3,])+1092))/2)
}

# remove circles from time series data
ea_resid_ts <- list()

for (i in names(resid_ts)) {
  ea_resid_ts[[i]] <- resid_ts[[i]][-c(circles_times[[i]][1,1]:(circles_times[[i]][1,1]+19),circles_times[[i]][1,2]:(circles_times[[i]][1,2]+19),
                         circles_times[[i]][1,3]:(circles_times[[i]][1,3]+19),circles_times[[i]][1,4]:(circles_times[[i]][1,4]+19),
                         circles_times[[i]][1,5]:(circles_times[[i]][1,5]+19),circles_times[[i]][1,6]:(circles_times[[i]][1,6]+19)),]
}


# check dims
lapply(ea_resid_ts, dim)

# check for NAs
for (i in names(ea_resid_ts)) {
  print (i)
  print(which(is.na(ea_resid_ts[[i]])))
}

```

```{r}
# read in behavioural data
spins_behav <- read.csv("/projects/loliver/SPINS_PLS_Conn/data/processed/spins_behav_data_full_11-20-2020.csv", header = T, stringsAsFactors = F)

# change IDs for participants with repeated scans (using prisma scans in these cases)
spins_behav[spins_behav$record_id=="SPN01_ZHH_0060","record_id"] <- "SPN01_ZHP_0060"
spins_behav[spins_behav$record_id=="SPN01_CMH_0180","record_id"] <- "SPN01_CMP_0180"
spins_behav[spins_behav$record_id=="SPN01_CMH_0182","record_id"] <- "SPN01_CMP_0182"
spins_behav[spins_behav$record_id=="SPN01_CMH_0196","record_id"] <- "SPN01_CMP_0196"
spins_behav[spins_behav$record_id=="SPN01_CMH_0198","record_id"] <- "SPN01_CMP_0198"
spins_behav[spins_behav$record_id=="SPN01_CMH_0207","record_id"] <- "SPN01_CMP_0207"
spins_behav[spins_behav$record_id=="SPN01_CMH_0211","record_id"] <- "SPN01_CMP_0211" 
spins_behav[spins_behav$record_id=="SPN01_CMH_0213","record_id"] <- "SPN01_CMP_0213"

# keep only participants we have EA connectivity data for
spins_behav_conn <- spins_behav[spins_behav$record_id %in% names(ea_resid_ts),]
case <- as.vector(spins_behav_conn[spins_behav_conn$diagnostic_group=="case","record_id"])
control <- as.vector(spins_behav_conn[spins_behav_conn$diagnostic_group=="control","record_id"])

# add mean EA to df
# find EA regressor files
setwd("/scratch/loliver/SPINS_PLS_Conn")
files_ea <- list.files(path= ".", recursive=T, full.names=F, pattern="^.*_EA\\.1D$")

# create list of IDs
ea_ptlist <- paste("SPN01", substring(files_ea,5,7), substring(files_ea,8,11), sep = "_")

# read in ea regressor files
ea <- lapply(files_ea, read.csv, header=F, sep="*")
ea <- lapply(ea, cSplit, splitCols=2:4, sep=":")
names(ea) <- ea_ptlist

# calculate mean EA and add to spins_behav_conn
spins_behav_conn$mean_ea <- NA

for (i in names(ea_resid_ts)) {
  spins_behav_conn[spins_behav_conn$record_id==i,"mean_ea"] <- mean(c(ea[[i]][[1,"V2_1"]],ea[[i]][[1,"V3_1"]],ea[[i]][[1,"V4_1"]],
    ea[[i]][[2,"V2_1"]],ea[[i]][[2,"V3_1"]],ea[[i]][[2,"V4_1"]],ea[[i]][[3,"V2_1"]],ea[[i]][[3,"V3_1"]],ea[[i]][[3,"V4_1"]]))
}

# fisher z transform EA values
spins_behav_conn$mean_ea <- fisherz(spins_behav_conn$mean_ea)

# write.csv(spins_behav_conn, file="/projects/loliver/SPINS_PLS_Conn/data/processed/spins_behav_ea_conn_04-29-2021.csv", row.names=F)

```

```{r}

# read in Glasser ROI labels (360)
rois <- read.csv(file = "/projects/loliver/SPINS_PLS_Conn/data/Glasser_roi_labels.csv", header=F, sep=" ")[c(TRUE, FALSE), 1]

# read in Alcala-Lopez et al. (2018) soc cog Glasser ROIs
# sc_rois <- read.csv(file = "/projects/loliver/SPINS_PLS_Conn/data/Glasser_Alcala-Lopez_scog_rois.csv", header=F)

# add labels to df columns
for (i in names(ea_resid_ts)) {
  colnames(ea_resid_ts[[i]]) <- as.vector(rois)
  ea_resid_ts[[i]] <- data.frame(ea_resid_ts[[i]])
}

# Generate correlation matrices for each participant (could use partial corrs here instead?)
ea_cor <- lapply(ea_resid_ts, correlate)

# set upper triangle to NA
ea_cor <- lapply(ea_cor, shave)

# example corr plot
rplot(ea_cor[[1]])

# create dfs with corrs for each participant
ea_cor_str <- lapply(ea_cor, stretch, na.rm=F)
ea_cor_stru <- lapply(ea_cor_str, unite, col="rois", 1:2, sep="-", remove=T)
ea_cor_df <- lapply(ea_cor_stru, data.frame)

# change col 1 to row names
cor_names <- as.vector(ea_cor_df[[1]][,1])

for (i in names(ea_cor_df)) {
  ea_cor_df[[i]] <- data.frame(ea_cor_df[[i]][,2])
  ea_cor_df[[i]] <- t(ea_cor_df[[i]])
  colnames(ea_cor_df[[i]]) <- cor_names
}

# bind rows across df list to generate tibble with all corrs for each participant
ea_corrs <- do.call("rbind",ea_cor_df)
rownames(ea_corrs) <- names(ea_cor_df)

# remove columns with only NAs
ea_corrs <- ea_corrs[,colSums(is.na(ea_corrs)) != nrow(ea_corrs)]

# fisher z transform corrs
ea_corrs_z  <- fisherz(ea_corrs)

```

```{r warning=FALSE}
# PLSC (Derek Beaton's pkg; symmetric analysis as per McIntosh et al., 1996)

# create separate X and Y matrices 
conn <- as.matrix(ea_corrs_z) # x var

beh <- as.matrix(spins_behav_conn[,c("scog_rmet_total","scog_er40_total","mean_ea","scog_tasit1_total","scog_tasit2_sinc",
          "scog_tasit2_simpsar","scog_tasit2_parsar","scog_tasit3_lie","scog_tasit3_sar",
          "np_domain_tscore_process_speed","np_domain_tscore_att_vigilance","np_domain_tscore_work_mem",
          "np_domain_tscore_verbal_learning","np_domain_tscore_visual_learning","np_domain_tscore_reasoning_ps")]) # y var
rownames(beh) <- spins_behav_conn$record_id
colnames(beh) <- c("RMET","ER40","EA","TASIT1","T2_sinc","T2_simsar","T2_parsar","T3_lie","T3_sar","Proc_Speed","Att_Vig","Work_Mem",
"Verb_Learn","Vis_Learn","Reason_PS") 

# explore rows with NAs
beh[!complete.cases(beh),] # 10 people missing at least one beh value

# ZHP_0110 and ZHP_0172 did not complete soc cog tasks - exclude these participants
beh <- beh[rownames(beh)!="SPN01_ZHP_0110" & rownames(beh)!="SPN01_ZHP_0172",]

# impute remaining NA values using mice (1 each for remaining 8 participants) 
# ppm (predictive mean matching) is default method; m = 5 is the default number of imputations
beh <- complete(mice(beh))

conn <- conn[rownames(conn) %in% rownames(beh),]

# generate table one
char_table <- spins_behav_conn[,c("record_id","diagnostic_group","demo_sex","demo_age_study_entry","scog_rmet_total","scog_er40_total",
          "mean_ea","scog_tasit1_total","scog_tasit2_sinc",
          "scog_tasit2_simpsar","scog_tasit2_parsar","scog_tasit3_lie","scog_tasit3_sar",
          "np_domain_tscore_process_speed","np_domain_tscore_att_vigilance","np_domain_tscore_work_mem",
          "np_domain_tscore_verbal_learning","np_domain_tscore_visual_learning","np_domain_tscore_reasoning_ps")]
char_table <- na.omit(char_table)
colnames(char_table) <- c("ID","Diagnostic_Group","Sex_at_birth","Age","RMET","ER40","EA","TASIT1","T2_sinc","T2_simsar","T2_parsar",
                          "T3_lie","T3_sar","Proc_Speed","Att_Vig","Work_Mem","Verb_Learn","Vis_Learn","Reason_PS") 

table_one <- CreateTableOne(strata="Diagnostic_Group",data=char_table[,2:19])

table = print(table_one)

#write.csv(table,file="/projects/loliver/SPINS_PLS_Conn/data/processed/tableone_04-30-2021.csv")


# examine covariance - maybe after so we can focus on most relevant variables
# ea_cbind(beh,conn)
library(eqs2lavaan)
beh_cor <- cor(beh)
beh_cov <- cov(beh)
corrplot(beh_cor,method="circle",tl.cex=.9,tl.col="black",type="upper")
plotCov(beh_cov)  # looks terrible

# run pls - include scaling as these variables have not been z-scored
# may want to revisit centering and scaling options, but these are per behavioural PLS in MATLAB (centered and normalized with sum of squares of each column equal to 1)
ea_plsc <- tepPLS(conn, beh, center1 = TRUE, scale1 = "SS1", center2 = TRUE, scale2 = "SS1", DESIGN=NULL, graphs=FALSE)

# permutation testing and scree plot to determine number of components
set.seed(999)
perm_ea_plsc <- perm4PLSC(conn, beh, center1 = TRUE, scale1 = "SS1", center2 = TRUE, scale2 = "SS1", nIter = 1000) 

#plot scree
PlotScree(ev = ea_plsc$TExPosition.Data$eigs, p.ev = perm_ea_plsc$pEigenvalues, plotKaiser = TRUE, col.ns = "black",
          col.sig = "red")

# plot scores ## these are appearing weirdly
LV1 <- cbind(ea_plsc$TExPosition.Data$lx[,1],ea_plsc$TExPosition.Data$ly[,1])
colnames(LV1) <- c("Lx_conn 1", "Ly_beh 1")
plot_LV1 <- createFactorMap(LV1) 

cor(ea_plsc$TExPosition.Data$lx[,1],ea_plsc$TExPosition.Data$ly[,1])
plot_LV1$zeMap_background + plot_LV1$zeMap_dots


LV2 <- cbind(ea_plsc$TExPosition.Data$lx[,2],ea_plsc$TExPosition.Data$ly[,2])
colnames(LV2) <- c("Lx_conn 2", "Ly_beh 2")
plot_LV2 <- createFactorMap(LV2, constraints = NULL)

cor(ea_plsc$TExPosition.Data$lx[,2],ea_plsc$TExPosition.Data$ly[,2])
plot_LV2$zeMap_background + plot_LV2$zeMap_dots

# salience plots and bootstrapping for contributor significance

# contributions/saliences (loadings) are absolute values, so need to get signs based on factor scores
Cx_conn <- ea_plsc$TExPosition.Data$ci * sign(ea_plsc$TExPosition.Data$fi)
Cy_beh <- ea_plsc$TExPosition.Data$cj * sign(ea_plsc$TExPosition.Data$fj)

# bootstrapped model
ea_plsc_boot <- Boot4PLSC(conn, beh, center1 = TRUE, scale1 = "SS1", center2 = TRUE, scale2 = "SS1", nIter = 1000,
  critical.value = 2, nf2keep = 3, alphaLevel = 0.05) 

```

```{r fig.height=6, fig.width=6}
# salience plots
# sig conn for LV1
names(which(ea_plsc_boot$bootRatiosSignificant.i[,1] == TRUE))

#LV1_Conn <- PrettyBarPlot2(bootratio = round(100000*Cx_conn[,1]), 
#            threshold = 100/nrow(Cx_conn),
#            signifOnly = TRUE,
#            plotnames = TRUE,
#            main = "Conn Factor Loadings LV1",
#            ylab = "Variable Factor Loadings")

# sig conn for LV2
names(which(ea_plsc_boot$bootRatiosSignificant.i[,2] == TRUE)) 

#LV2_Conn <- PrettyBarPlot2(bootratio = round(100*Cx_conn[,2]), 
#            plotnames = TRUE,
#            signifOnly = TRUE,
#            main = "Conn Factor Loadings LV2",
#            ylab = "Variable Factor Loadings")


# sig beh for LV1
names(which(ea_plsc_boot$bootRatiosSignificant.j[,1] == TRUE))

PrettyBarPlot2(bootratio = round(100*Cy_beh[,1]),
            threshold = 2,
            plotnames = TRUE,
            font.shrink = 0,
            font.size = 7,
            main = "Beh Factor Loadings LV1",
            ylab = "Variable Factor Loadings") +
            theme(axis.text.y = element_text(size=16))

# sig beh for LV2
names(which(ea_plsc_boot$bootRatiosSignificant.j[,2] == TRUE))

PrettyBarPlot2(bootratio = round(100*Cy_beh[,2]),
            threshold = 7.5,
            plotnames = TRUE,
            font.shrink = 0,
            font.size = 7,
            main = "Beh Factor Loadings LV2",
            ylab = "Variable Factor Loadings") +
            theme(axis.text.y = element_text(size=16))


```

```{r}
# Visualize conn findings

# Get glasser atlas (hcp_mmp1.0) info and output csv
library(brainGraph)
glasser_info <- data.frame(hcp_mmp1.0[1:360])

#write.csv <- write.csv(glasser_info, file="/projects/loliver/SPINS_PLS_Conn/data/Glasser_roi_info_brainGraph.csv", row.names=T)

# Generate matrices with salience values for sig contributors for LV1
ea_conn_LV1 <- unite(ea_cor_str[[1]], col="rois", 1:2, sep="-", remove=F)

# change r values to saliences for significant connections - the saliences are very small values, hence the x10000 for visualization
# divided by 3.5 to limit the range between 0 and 1 for plot alpha
ea_conn_LV1[ea_conn_LV1$rois %in% names(which(ea_plsc_boot$bootRatiosSignificant.i[,1] == TRUE)), "r"] <- 10000*(Cx_conn[rownames(Cx_conn) %in% names(which(ea_plsc_boot$bootRatiosSignificant.i[,1] == TRUE)),1])/3.5

# make all other connections 0
ea_conn_LV1[!(ea_conn_LV1$rois %in% names(which(ea_plsc_boot$bootRatiosSignificant.i[,1] == TRUE))), "r"] <- 0

# visualize LV1 conn results
library(tidygraph)
library(ggraph)

# convert to tbl_graph tidygraph object and add other node info - filter out non-sig nodes
tg_ea_conn_LV1 <- as_tbl_graph(ea_conn_LV1[,2:4], directed=F) %>% activate(nodes) %>% 
  mutate(roi=glasser_info$name, lobe=as.factor(glasser_info$lobe), 
  hemi=as.factor(glasser_info$hemi), area=as.factor(glasser_info$area)) %>%
  activate(edges) %>% mutate(val = case_when(r>0 ~ "pos", r<0 ~ "neg", r==0 ~ "ns"), r=abs(r)) %>%
  filter(val != "ns")

# swirly plot - index value refersto node location - 30233 sig pos conns vs 575 sig neg conns (hence all blue)
ggraph(tg_ea_conn_LV1, layout="linear", sort.by='lobe') +
  geom_edge_arc(aes(colour=val),alpha=0.03) + # width=r
  geom_node_point(aes(colour=lobe), size=4.5) +
  theme_minimal() + 
  theme(panel.border = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 
  
  scale_edge_alpha_continuous(range=c(0,1)) +
  scale_edge_width_continuous(range = c(1,3))

ggraph(tg_ea_conn_LV1) + 
  geom_edge_link() + 
  geom_node_point()


# Old corr plots
# convert back to correlation matrix 
ea_cor_conn_LV1 <- data.frame(retract(ea_conn_LV1[,2:4]))
ea_cor_conn_LV1 <- cbind(ea_cor_conn_LV1$term,(ea_cor_conn_LV1[,2:361]/1.7)) # this was done to limit the range between -1 and 1 for corrplot and rplot
colnames(ea_cor_conn_LV1)[1] <- "term"

ea_cormat_conn_LV1 <- as.matrix(ea_cor_conn_LV1[,2:361])
rownames(ea_cormat_conn_LV1) <- ea_cor_conn_LV1$term
ea_cormat_conn_LV1 <- ea_cormat_conn_LV1/1.7 # same as above re the range

rplot(ea_cor_conn_LV1[1:360,c(1:361)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 6))

rplot(ea_cor_conn_LV1[1:180,c(1:181)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 5.5))

rplot(ea_cor_conn_LV1[1:120,c(1:121)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))

rplot(ea_cor_conn_LV1[1:120,c(1:121)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))

rplot(ea_cor_conn_LV1[121:240,c(1,122:241)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))

rplot(ea_cor_conn_LV1[241:360,c(1,242:361)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))
  

# same for LV2
ea_conn_LV2 <- unite(ea_cor_str[[1]], col="rois", 1:2, sep="-", remove=F)

# change r values to saliences for significant connections
ea_conn_LV2[ea_conn_LV2$rois %in% names(which(ea_plsc_boot$bootRatiosSignificant.i[,2] == TRUE)), "r"] <- 10000*(Cx_conn[rownames(Cx_conn) %in% names(which(ea_plsc_boot$bootRatiosSignificant.i[,2] == TRUE)),2])/3.5

# make all other connections 0
ea_conn_LV2[!(ea_conn_LV2$rois %in% names(which(ea_plsc_boot$bootRatiosSignificant.i[,2] == TRUE))), "r"] <- 0

# create vector of non-zero values
strength <- data.frame(ea_conn_LV2[ea_conn_LV2$r!=0,"r"])

# visualize LV2 conn results
# convert to tbl_graph tidygraph object and add other node info - filter out non-sig nodes
tg_ea_conn_LV2 <- as_tbl_graph(ea_conn_LV2[,2:4], directed=F) %>% activate(nodes) %>% 
  mutate(roi=glasser_info$name, lobe=as.factor(glasser_info$lobe), 
  hemi=as.factor(glasser_info$hemi), area=as.factor(glasser_info$area)) %>%
  activate(edges) %>% mutate(val = case_when(r>0 ~ "pos", r<0 ~ "neg", r==0 ~ "ns"), r=abs(r)) %>%
  filter(val != "ns")

# swirly plot - index value refersto node location # curvature should control edge being above or below but doesn't seem to work
ggraph(tg_ea_conn_LV2, layout="linear", sort.by='lobe') +
  geom_edge_arc(aes(colour=val),alpha=0.03,curvature=sign(strength$r)) + #curvature=sign(strength$r) ,width=r/5
  geom_node_point(aes(colour=lobe), size = 4.5) +
  #scale_edge_width_continuous(range = c(0,1)) +
  theme_minimal() +  
  theme(panel.border = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_blank(),
        axis.text.x  = element_blank(),
        axis.text.y  = element_blank()) 


# old corr plots
# convert back to correlation matrix
ea_cor_conn_LV2 <- data.frame(retract(ea_conn_LV2[,2:4]))
ea_cor_conn_LV2 <- cbind(ea_cor_conn_LV2$term,(ea_cor_conn_LV2[,2:361]/2)) # range restriction
colnames(ea_cor_conn_LV2)[1] <- "term"

rplot(ea_cor_conn_LV2) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))

rplot(ea_cor_conn_LV2[1:180,c(1:181)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 5.5))

rplot(ea_cor_conn_LV2[1:120,c(1:121)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))

rplot(ea_cor_conn_LV2[121:240,c(1,122:241)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))

rplot(ea_cor_conn_LV2[241:360,c(1,242:361)]) +
theme(axis.text.x = element_text(angle = 90),axis.text = element_text(size = 7))

```


```{r}
# PLSC with only soc cog beh variables

# create separate X and Y matrices 
sc_conn <- conn # x var
sc_beh <- beh[,1:9] # y var


# yeo johnson family transform beh variables - decide whether we want to do this (and do above as well if so) - skip for now
get_pT_yj <- function(x) {
  pT <- x^powerTransform(x,family="yjPower")$lambda
  return(pT)
}

sc_beh <- apply(sc_beh,2,get_pT_yj)


# examine covariance - maybe after so we can focus on most relevant variables

# run pls including centering and scaling, per behavioural PLS in MATLAB - centered and normalized with sum of squares of each column equal to 1
ea_sc_plsc <- tepPLS(sc_conn, sc_beh, center1 = TRUE, scale1 = "SS1", center2 = TRUE, scale2 = "SS1", DESIGN=NULL, graphs=FALSE)

# permutation testing and scree plot to determine number of components
set.seed(999)
perm_ea_sc_plsc <- perm4PLSC(sc_conn, sc_beh, center1 = TRUE, scale1 = "SS1", center2 = TRUE, scale2 = "SS1", nIter = 500) 

#plot scree
PlotScree(ev = ea_sc_plsc$TExPosition.Data$eigs, p.ev = perm_ea_sc_plsc$pEigenvalues, plotKaiser = TRUE, col.ns = "black",
          col.sig = "red")

# plot scores ## these are appearing weirdly - need to try altering y axis again
sc_LV1 <- cbind(ea_sc_plsc$TExPosition.Data$lx[,1],ea_sc_plsc$TExPosition.Data$ly[,1])
colnames(sc_LV1) <- c("Lx_conn 1", "Ly_beh 1")
plot_sc_LV1 <- createFactorMap(sc_LV1) 

cor(ea_sc_plsc$TExPosition.Data$lx[,1],ea_sc_plsc$TExPosition.Data$ly[,1])
plot_sc_LV1$zeMap_background + plot_sc_LV1$zeMap_dots


sc_LV2 <- cbind(ea_sc_plsc$TExPosition.Data$lx[,2],ea_sc_plsc$TExPosition.Data$ly[,2])
colnames(sc_LV2) <- c("Lx_conn 2", "Ly_beh 2")
plot_sc_LV2 <- createFactorMap(sc_LV2, constraints = NULL)

cor(ea_sc_plsc$TExPosition.Data$lx[,2],ea_sc_plsc$TExPosition.Data$ly[,2])
plot_sc_LV2$zeMap_background + plot_sc_LV2$zeMap_dots


# salience plots and bootstrapping for contributor significance
# contributions/saliences (loadings) are absolute values, so need to get signs based on factor scores
Cx_sc_conn <- ea_sc_plsc$TExPosition.Data$ci * sign(ea_sc_plsc$TExPosition.Data$fi)
Cy_sc_beh <- ea_sc_plsc$TExPosition.Data$cj * sign(ea_sc_plsc$TExPosition.Data$fj)

# bootstrapped model
ea_sc_plsc_boot <- Boot4PLSC(sc_conn, sc_beh, center1 = TRUE, scale1 = "SS1", center2 = TRUE, scale2 = "SS1", nIter = 1000,
  critical.value = 2, nf2keep = 3, alphaLevel = 0.05)

```

```{r}
# salience plots
# sig conn for LV1
names(which(ea_sc_plsc_boot$bootRatiosSignificant.i[,1] == TRUE))

#LV1_sc_Conn <- PrettyBarPlot2(bootratio = round(100*Cx_sc_conn[,1]), 
#            threshold = 100/nrow(Cx_sc_conn),
#            #signifOnly = TRUE,
#            plotnames = TRUE,
#            main = "Conn Factor Loadings LV1",
#            ylab = "Variable Factor Loadings")

# sig conn for LV2
names(which(ea_sc_plsc_boot$bootRatiosSignificant.i[,2] == TRUE))

#LV2_sc_Conn <- PrettyBarPlot2(bootratio = round(100*Cx_sc_conn[,2]), 
#            plotnames = TRUE,
#            signifOnly = TRUE,
#            main = "Conn Factor Loadings LV2",
#            ylab = "Variable Factor Loadings")


# sig beh for LV1
names(which(ea_sc_plsc_boot$bootRatiosSignificant.j[,1] == TRUE))

PrettyBarPlot2(bootratio = round(100*Cy_sc_beh[,1]), 
            plotnames = TRUE,
            main = "Beh Factor Loadings LV1",
            ylab = "Variable Factor Loadings")

# sig beh for LV2
names(which(ea_sc_plsc_boot$bootRatiosSignificant.j[,2] == TRUE))

PrettyBarPlot2(bootratio = round(100*Cy_sc_beh[,2]), 
            plotnames = TRUE,
            main = "Beh Factor Loadings LV2",
            ylab = "Variable Factor Loadings")

```


```{r}

```


```{r}
# visualize time series for EA in Glasser ROIs - can try later

for (i in names(EA_resid_ts)) {
  EA_resid_ts_melt[[i]]$TR <- 1:819 
  EA_resid_ts_melt[[i]] <- melt(EA_resid_ts_melt[[i]],id="TR")
}

for (i in names(resid_times_rois_melt)) {
  ggplot(data.frame(resid_times_rois_melt[[i]]), aes(x = Sub.brick, y = value, group = 1)) + geom_line() + facet_wrap("variable") + ggtitle(i)
}


```

```{r}
# visualize correlation matrix for each participant
for (i in names(cor_EA_diag[1:50])) {
  corrplot(cor_EA[[i]], method="color",type="lower",tl.cex=.6,tl.col="black",title=i)
}

corrplot(cor_EA[["SPN01_CMH_0159"]], method="color",type="lower",tl.cex=.6,tl.col="black")
corrplot(cor_EA[["SPN01_ZHP_0123"]], method="color",type="lower",tl.cex=.6,tl.col="black")
```


```{r}

```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
